\chapter{ΕΡΩΤΗΜΑ 2}

    \section{ΟΡΙΣΜΟΣ ΤΑΞΙΝΟΜΗΤΩΝ}

    Στην συνάρτηση \verb|get_classifier(option)| ορίζονται και μπορούν να επιλεχθούν οι ταξινομητές που θα χρησιμοποιηθούν στη συνέχεια.

    Σε κάθε περίπτωση ταξινομητή, σε καθένα από τα 22 dataframes του dataset αφαιρείται η στήλη \texttt{timestamp},
    και το dataframe διαχωρίζεται από τη στήλη \texttt{label} στα \texttt{X} και \texttt{Y}. Όταν γίνει ο διαχωρισμός, γίνονται split
    στα dataframes \texttt{X\_train}, \texttt{X\_test}, \texttt{Y\_train}, \texttt{Y\_test} με \verb|test_size = 0.3|.

    Αφού γίνει η επιλογή του classifier, αυτός γίνεται train μέσω της \verb|fit(X_train, Y_train)| και αποθηκεύονται τα predictions του μέσω της \verb|predict(X_test)|.

    \section{ΑΠΟΤΕΛΣΜΑΤΑ}

        Τρέχουμε κάθε classifier για όλους τους συμμετέχοντες:

    \subsection{NEURAL NETWORKS}

        \begin{table}[ht] \noindent\centering\tt
        \resizebox{0.5\textwidth}{!}{
            \begin{tabular}{lrr}
                file & training accuracy & testing accuracy \\
                \midrule
                S006.csv & 0.9141337173536156 & 0.9122442155399509 \\
                S008.csv & 0.9329507794280103 & 0.9315337677112421 \\
                S009.csv & 0.8956013466020495 & 0.8916271040138111 \\
                S010.csv & 0.8519300925436921 & 0.8499360159249254 \\
                S012.csv & 0.9738502515979364 & 0.9730834604488996 \\
                S013.csv & 0.9007985198546176 & 0.8996423539612008 \\
                S014.csv & 0.8991970063148047 & 0.8973778274987039 \\
                S015\_fix.csv & 0.9135976563300259 & 0.9136856865150815 \\
                S016.csv & 0.9141337173536156 & 0.9447883255491156 \\
                S017.csv & 0.9329507794280103 & 0.9109135048143804 \\
                S018.csv & 0.8956013466020495 & 0.8708032518979748 \\
                S019.csv & 0.8519300925436921 & 0.9578000537008861 \\
                S020.csv & 0.9542851869085204 & 0.9545083401376414 \\
                S021\_fix.csv & 0.9347834306997145 & 0.9334105321202095 \\
                S022.csv & 0.9020188641720371 & 0.9002873194379992 \\
                S023\_fix.csv & 0.9318747924277648 & 0.9256308422531119 \\
                S024.csv & 0.9218583766848449 & 0.9191376243623073 \\
                S025.csv & 0.8687010665187103 & 0.8650728577798875 \\
                S026.csv & 0.8737227345922998 & 0.8699446645716628 \\
                S027.csv & 0.9876495387719804 & 0.9867580292584497 \\
                S028.csv & 0.9772106137134159 & 0.9761270533155749 \\
                S029.csv & 0.9475463825229214 & 0.9443625850974541
            \end{tabular}}
        \end{table}

    \subsection{RANDOM FOREST}

        \begin{table}[H] \noindent\centering\tt
        \resizebox{0.5\textwidth}{!}{
            \begin{tabular}{lrr}
                file & training accuracy & testing accuracy \\
                \midrule
                S006.csv & 1.0 & 0.9306598810892809 \\
                S008.csv & 1.0 & 0.9432683357598033 \\
                S009.csv & 0.9999907513595502 & 0.8979499352611136 \\
                S010.csv & 0.9999918750050781 & 0.8659367742547041 \\
                S012.csv & 0.9999962643216569 & 0.9788363477881892 \\
                S013.csv & 1.0 & 0.9186264947075612 \\
                S014.csv & 1.0 & 0.9186264947075612 \\
                S015\_fix.csv & 0.9999863422495681 & 0.9243216112430089 \\
                S016.csv & 1.0 & 0.9555080374392737 \\
                S017.csv & 0.9999922065574026 & 0.9255794077266487 \\
                S018.csv & 0.9999955671597462 & 0.8967336215634761 \\
                S019.csv & 0.9999952052397141 & 0.9646916674125123 \\
                S020.csv & 1.0 & 0.959730459672137 \\
                S021\_fix.csv & 1.0 & 0.9460601047697822 \\
                S022.csv & 1.0 & 0.9111284446243619 \\
                S023\_fix.csv & 0.9999896213882431 & 0.9385867196202838 \\
                S024.csv & 0.999983245792599 & 0.9339926897441411 \\
                S025.csv & 0.999987670303927 & 0.8797307210978293 \\
                S026.csv & 0.999992680427463 & 0.8916006285011614 \\
                S027.csv & 1.0 & 0.9887968723726248 \\
                S028.csv & 0.9999827025531032 & 0.9785890140049239 \\
                S029.csv & 1.0 & 0.9555348316702416 \\
            \end{tabular}}
        \end{table}

    \pagebreak
    \subsection{BAYESIAN NETWORKS}

        \begin{table}[ht] \noindent\centering\tt
        \resizebox{0.5\textwidth}{!}{
            \begin{tabular}{lrr}
                file & training accuracy & testing accuracy \\
                \midrule
                S006.csv & 0.8708720149879761 & 0.8709109148295858 \\
                S008.csv & 0.8950056598884388 & 0.8940945289068156 \\
                S009.csv & 0.8275868447338242 & 0.8281398359948209 \\
                S010.csv & 0.7653420216612364 & 0.7660552632826201 \\
                S012.csv & 0.9394446540575070 & 0.9392373066027457 \\
                S013.csv & 0.8135999969034615 & 0.8122538925616849 \\
                S014.csv & 0.8498128946752943 & 0.8503005993797011 \\
                S015\_fix.csv & 0.8722966190238806 & 0.8719307191000494 \\
                S016.csv & 0.8932883694009454 & 0.8942753174647835 \\
                S017.csv & 0.8588490643972162 & 0.8601511142631134 \\
                S018.csv & 0.7839300675121571 & 0.7838997952048985 \\
                S019.csv & 0.8906698759595514 & 0.8916248993108387 \\
                S020.csv & 0.9124273688986991 & 0.9138529731087762 \\
                S021\_fix.csv & 0.8831981547652809 & 0.8823821339950372 \\
                S022.csv & 0.8233673689600163 & 0.8252288188307777 \\
                S023\_fix.csv & 0.7625996346728662 & 0.7668668571705333 \\
                S024.csv & 0.7699228468749215 & 0.7724438537166982 \\
                S025.csv & 0.6912890697244313 & 0.6867043542053252 \\
                S026.csv & 0.7031474161908945 & 0.7008300314250581 \\
                S027.csv & 0.9621288555779763 & 0.9618715318648058 \\
                S028.csv & 0.9570936829723933 & 0.9572385680267991 \\
                S029.csv & 0.7504656237759890 & 0.7464329012403246 \\
            \end{tabular}}
        \end{table}

\subsection{ΜΕΣΟΙ ΟΡΟΙ}

        Αυτός είναι ο μέσος όρος των αποτελεσμάτων των μοντέλων:
        \begin{table}[ht] \noindent\centering\tt
        \resizebox{\textwidth}{!}{
            \begin{tabular}{llrrrrr}
                 & classifier & score & accuracy & precision & recall & f1 \\
                \midrule
                1 & MLPClassifier & 0.9215787974 & 0.9197436955 & 0.7644127233 & 0.6806597787 & 0.6976677241 \\
                2 & RandomForestClassifier & 0.9999962322 & 0.9317139313 & 0.8322693957 & 0.7073846769 & 0.7384389196 \\
                3 & GaussianNB & 0.8403413636 & 0.8403609059 & 0.5568391564 & 0.5460153011 & 0.5208372416 \\
            \end{tabular}}
        \end{table}

        \begin{multicols}{2} \centering \noindent
            \includegraphics[scale=0.5]{img/models_train_test}
            \includegraphics[scale=0.5]{img/models_metrics}
        \end{multicols}

\section{ΣΥΜΠΕΡΑΣΜΑΤΑ}
    Παρατηρούμε πως το training accuracy του Random Forest είναι σχεδόν τέλειο, και μεγαλύτερο από το testing accuracy.
    Αυτό μας οδηγεί στο συμπέρασμα πως είναι πιθανό να υπάρχει overfitting· υπάρχει υπερβολικά καλή απόδοση στα training δεδομένα και δεν γενικεύει αρκετά ώστε να ανταποκρίνεται στα test δεδομένα.
    Σε συνδυασμό με την μικρότερη ακρίβεια των Bayesian Networks, η καλύτερη δυνατή επιλογή είναι τα Neural Networks.